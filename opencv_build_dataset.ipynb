{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n",
    "\n",
    "OpenCV supports a wide variety of programming languages such as C++, Python, Java, etc., and is available on different platforms including Windows, Linux, OS X, Android, and iOS.\n",
    "\n",
    "OpenCV-Python makes use of Numpy, which is a highly optimized library for numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open webcam and capture a frame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection using Haar Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of available pretraied models in OpenCV:\n",
    "\n",
    "<div style=\"float: left; width: 50%\">\n",
    "<ul>\n",
    "    <li> haarcascade_eye_tree_eyeglasses  \n",
    "    <li> haarcascade_mcs_leftear\n",
    "    <li> haarcascade_eye                  \n",
    "    <li> haarcascade_mcs_lefteye\n",
    "    <li> haarcascade_frontalface_alt2   \n",
    "    <li> haarcascade_mcs_mouth\n",
    "    <li> haarcascade_frontalface_alt_tree\n",
    "    <li> haarcascade_mcs_nose\n",
    "    <li> <font style=\"color: #be2830\">haarcascade_frontalface_alt</font>       \n",
    "    <li> haarcascade_mcs_rightear\n",
    "    <li> haarcascade_frontalface_default\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%\">\n",
    "<ul>\n",
    "    <li> haarcascade_mcs_righteye\n",
    "    <li> haarcascade_fullbody            \n",
    "    <li> haarcascade_mcs_upperbody\n",
    "    <li> haarcascade_lefteye_2splits    \n",
    "    <li> haarcascade_profileface\n",
    "    <li> haarcascade_lowerbody            \n",
    "    <li> haarcascade_righteye_2splits\n",
    "    <li> haarcascade_mcs_eyepair_big     \n",
    "    <li> haarcascade_smile\n",
    "    <li> haarcascade_mcs_eyepair_small\n",
    "    <li> haarcascade_upperbody\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Faces with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detector = cv2.CascadeClassifier( xml_file_path)\n",
    "\n",
    "### face_coord = detector.detectMultiScale(image, scale_factor, min_neighbors, min_size, max_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image : gray scale image where face are detected.\n",
    "\n",
    "\n",
    "#### scale_factor:Parameter specifying how much the image size is reduced at each image scale.\n",
    "\n",
    "\n",
    "#### minNeighbors – Parameter specifying how many neighbors each candidate rectangle should have to retain it.\n",
    "\n",
    "\n",
    "#### minSize – Minimum possible object size. Objects smaller than that are ignored.\n",
    "\n",
    "\n",
    "#### maxSize – Maximum possible object size. Objects larger than that are ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Build Our Dataset</h2>\n",
    "<h4 align=\"center\">\n",
    "Detect $\\rightarrow$ Cut $\\rightarrow$ Normalize $\\rightarrow$ Resize $\\rightarrow$ Save</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "    if frame.ndim!=2:\n",
    "#         print('IF', frame.ndim)\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "#     print('Outer = ',frame.ndim)\n",
    "    detector = cv2.CascadeClassifier(\"xml/frontal_face.xml\")\n",
    "\n",
    "    faces = detector.detectMultiScale(frame,1.2,5)\n",
    "    \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    if image.ndim!=2:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_faces(image, faces_coord):\n",
    "    faces = []\n",
    "      \n",
    "    for (x, y, w, h) in faces_coord:\n",
    "        \n",
    "        faces.append(image[y: y + h, x : x + w ])\n",
    "         \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize faces by increasing pixel intensity(brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_intensity(images):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        is_color = len(image.shape) == 3 \n",
    "        if is_color:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        # Or \n",
    "#       if image.ndim!=2:\n",
    "#           image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        images_norm.append(cv2.equalizeHist(image))\n",
    "    return images_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize\n",
    "\n",
    "#### cv.INTER_AREA for shrinking & cv.INTER_CUBIC for zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(images,size=(47,62)):\n",
    "    image_resize = []\n",
    "    \n",
    "    for image in images:\n",
    "        if image.shape < size:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_CUBIC)\n",
    "        else:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_AREA)\n",
    "        image_resize.append(img_size)\n",
    "        \n",
    "    return image_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_faces(frame, faces_coord):\n",
    "    gray_frame = gray_scale(frame)\n",
    "    faces = cut_faces(gray_frame, faces_coord)\n",
    "    faces = normalize_intensity(faces)\n",
    "    \n",
    "    faces = resize(faces)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_show(image,title=\"\"):\n",
    "    if len(image.shape) == 3: # BGR is 3D and RGB is 2D\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.axis(\"off\") # o, 10, 20, 30 nhi show hoga\n",
    "    plt.title(title)\n",
    "    plt.imshow(image,cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, coords):\n",
    "    for (x, y, w, h) in coords:\n",
    "        #w_rm = int(0.2 * w / 2) \n",
    "        cv2.rectangle(image, (x , y), (x + w , y + h), (0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "#cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "folder = \"people/\"+input('Person:').lower()\n",
    "\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "    flag_start_capturing = False\n",
    "    sample=1\n",
    "    #cam = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    while True:\n",
    "        ret,frame = cam.read()\n",
    "        \n",
    "        \n",
    "        \n",
    "        faces_coord = detect_face(frame)\n",
    "\n",
    "        if len(faces_coord):\n",
    "            faces = normalize_faces(frame,faces_coord)\n",
    "            #faces = normalize_intensity(faces)\n",
    "            cv2.imwrite(folder + '/' + str(sample)+'.jpg',faces[0])\n",
    "            plot_show(faces[0],\"Image saved:\"+str(sample))\n",
    "            clear_output(wait=True)\n",
    "            if flag_start_capturing == True:\n",
    "                sample += 1\n",
    "            \n",
    "        draw_rectangle(frame,faces_coord)\n",
    "        cv2.imshow('Face',frame)\n",
    "        keypress=cv2.waitKey(1)\n",
    "        \n",
    "        if keypress == ord('c'):\n",
    "            \n",
    "            if flag_start_capturing == False:\n",
    "                flag_start_capturing = True\n",
    "            \n",
    "        \n",
    "        if sample >15:\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print (\"This name already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset for unknown people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### datasets for other class\n",
    "\n",
    "basepath = 'C:\\\\Users\\\\ashut\\\\scikit_learn_data\\\\lfw_home\\\\lfw_funneled\\\\'\n",
    "#C:\\Users\\Vineet\\scikit_learn_data\\lfw_home\n",
    "images = os.listdir(basepath) \n",
    "print (len(images))\n",
    "data = images[:210]\n",
    "\n",
    "for i,folder in enumerate(data,start=1):\n",
    "    \n",
    "    files=os.listdir(basepath+'\\\\'+folder)\n",
    "    for k,img in enumerate(files,start=1):\n",
    "        if img.endswith('.jpg'):\n",
    "            #print img\n",
    "            frame=cv2.imread(basepath+'\\\\'+folder+'\\\\'+img,0) # 0 --> gray scale\n",
    "        #print frame\n",
    "       \n",
    "            faces_coord = detect_face(frame)\n",
    "            if len(faces_coord):\n",
    "                faces = cut_faces(frame, faces_coord)\n",
    "                #print faces\n",
    "                faces = normalize_intensity(faces)\n",
    "                faces = resize(faces)\n",
    "                cv2.imwrite('people/unknown/' + str(i)+'.jpg',faces[0])\n",
    "                \n",
    "                break # Bs 1 pic hi read krega 1 folder se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    labels_dic = {}\n",
    "    #people = [person for person in os.listdir(\"Male_female/\")]\n",
    "    people = [person for person in os.listdir(\"people/\")] # fetch all folders from people, list form \n",
    "    #people = [person for person in os.listdir(\"people/\")]\n",
    "    for i, person in enumerate(people):\n",
    "        labels_dic[i] = person\n",
    "        for image in os.listdir(\"people/\" + person):\n",
    "            if image.endswith('.jpg'):\n",
    "                images.append(cv2.imread(\"people/\" + person + '/' + image, 0))\n",
    "                labels.append(i)\n",
    "    return (images, np.array(labels), labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, labels_dic = collect_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454\n",
      "{0: 'ashu', 1: 'ashu1', 2: 'ashutosh', 3: 'unknown', 4: 'vineet', 5: 'xyz'}\n"
     ]
    }
   ],
   "source": [
    "print (len(images))\n",
    "print (labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.asarray(images) # change list of array into single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 62, 47)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=X_train.reshape(len(X_train),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 2914)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=.97)\n",
    "new_train=pca1.fit_transform(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[.0001,.001,.01,.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svc = GridSearchCV(SVC(kernel='linear',probability=True),param_grid=param_grid,cv=kf,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc.fit(new_train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9801762114537445"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.0001}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=gs_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle to store python object\n",
    "\n",
    "filename = 'svc_linear_face.pkl'\n",
    "f=open(filename, 'wb')\n",
    "pickle.dump(clf,f)\n",
    " \n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svc_linear_face.pkl'\n",
    "svc1 = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5         3.18096472  5.31382703  4.25617816  1.97061164  0.77841846]]\n",
      "[[0.01270977 0.1637195  0.38947188 0.33814631 0.05674082 0.03921171]]\n",
      "[2] 2\n",
      "Ashutosh\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "font= cv2.FONT_HERSHEY_PLAIN\n",
    "cv2.namedWindow(\"opencv_face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    \n",
    "    \n",
    "    faces_coord = detect_face(frame) # detect more than one face\n",
    "    if len(faces_coord):\n",
    "        faces = normalize_faces(frame, faces_coord)\n",
    "        #faces = normalize_intensity(faces)\n",
    "        for i, face in enumerate(faces): # for each detected face\n",
    "            \n",
    "            \n",
    "            #cv2.imwrite('trainingData/female/picture_BGR5.jpg',face)\n",
    "            t=face.reshape(1,-1)\n",
    "            t=sc.transform(t.astype(np.float64))\n",
    "            test = pca1.transform(t)    \n",
    "            #print test\n",
    "            #transform = test.reshape(1,-1)\n",
    "            #print transform\n",
    "            prob=svc1.predict_proba(test)\n",
    "            confidence = svc1.decision_function(test)\n",
    "            print (confidence)\n",
    "            print (prob)\n",
    "           \n",
    "            \n",
    "            \n",
    "            pred = svc1.predict(test)\n",
    "            print (pred,pred[0])\n",
    "           \n",
    "            name=labels_dic[pred[0]].capitalize()\n",
    "            print (name)\n",
    "            \n",
    "            #pred = labels_dic[pred[0]].capitalize()\n",
    "            #threshold = .50\n",
    "            \n",
    "                \n",
    "                \n",
    "            cv2.putText(frame,name,(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                       cv2.FONT_HERSHEY_PLAIN, 2, (66, 53, 243), 2)\n",
    "            \n",
    "                \n",
    "           \n",
    "           # if prob[0][1]>.85:\n",
    "                \n",
    "            #    cv2.putText(frame, 'vineet',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "             #               cv2.FONT_HERSHEY_PLAIN, 2, (66, 53, 243), 2)\n",
    "            \n",
    "                \n",
    "            #else:\n",
    "             #   cv2.putText(frame,'unknown',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "              #              cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "                \n",
    "                \n",
    "           \n",
    "        clear_output(wait = True)\n",
    "        draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "        \n",
    "    cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2,\n",
    "                cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"opencv_face\", frame) # live feed in external\n",
    "    if cv2.waitKey(5) == 27:\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
